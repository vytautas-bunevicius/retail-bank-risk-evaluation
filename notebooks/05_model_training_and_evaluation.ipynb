{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This notebook builds upon the feature-engineered dataset from the previous notebook (`04_feature_engineering.ipynb`) and focuses on **Model Training and Evaluation**. Our primary goal is to develop a credit risk prediction model that excels at identifying potential loan defaulters, thereby minimizing financial losses for retail banks while also considering their desired balance between risk aversion and loan approval rates. This translates to maximizing the recall of the positive class (loan defaulters) while maintaining acceptable precision and overall model performance.\n",
    "\n",
    "### 0.5.1 Objectives\n",
    "\n",
    "The main objectives of this notebook are:\n",
    "\n",
    "1. **Model Selection:** Choose algorithms suitable for imbalanced classification problems.\n",
    "2. **Model Training:** Train models with a focus on identifying potential defaulters.\n",
    "3. **Hyperparameter Tuning:** Optimize models to increase recall for the positive class.\n",
    "4. **Model Evaluation:** Assess models primarily on recall, while considering precision, F2-score, AUC-PR, and overall performance.\n",
    "5. **Model Comparison:** Compare different models based on their ability to identify true positives and balance the precision-recall trade-off.\n",
    "6. **Threshold Adjustment:** Explore the impact of classification thresholds on recall and precision, collaborating with retail banks to determine the optimal threshold.\n",
    "\n",
    "### 0.5.2 Importance of Focusing on Recall\n",
    "\n",
    "Prioritizing recall for defaulter prediction is crucial for minimizing financial losses, which is the primary business objective in credit risk assessment. The cost of missing a potential defaulter (false negative) is typically much higher than the cost of incorrectly classifying a non-defaulter as high-risk (false positive). While we prioritize recall, we will also carefully consider the precision-recall trade-off and aim for a model that maximizes recall without severely impacting precision. Techniques like threshold adjustment and cost-sensitive learning will be used to balance these metrics effectively. Furthermore, demonstrating a thorough approach to risk identification aligns with regulatory expectations in the financial sector, supporting the banks' compliance needs. This approach also allows for more conservative lending practices, which can be adjusted based on the bank's specific risk tolerance.\n",
    "\n",
    "### 0.5.3 Our Approach\n",
    "\n",
    "In this notebook, we will focus on the following modeling tasks:\n",
    "\n",
    "1. **Data Preparation:** Address class imbalance using techniques like SMOTE or class weighting.\n",
    "2. **Baseline Model:** A logistic regression model with class weights inversely proportional to class frequencies will serve as our baseline. This will provide a benchmark for evaluating more complex models.\n",
    "3. **Advanced Models:** Train and evaluate models known for handling imbalanced data:\n",
    "   - Decision Trees with adjusted class weights\n",
    "   - Random Forest with balanced class weights\n",
    "   - Gradient Boosting (XGBoost, LightGBM) with `scale_pos_weight` adjustment\n",
    "4. **Hyperparameter Tuning:** We will employ techniques like GridSearchCV or RandomizedSearchCV, optimizing for the F2-score (which gives more weight to recall) or a custom cost-sensitive scoring function.\n",
    "5. **Model Evaluation:** Prioritize recall in our metrics, while also considering precision, F2-score, AUC-PR, and AUC-ROC.\n",
    "6. **Threshold Adjustment:** We will experiment with different classification thresholds and work closely with retail banks to determine the optimal threshold that balances their desired level of risk aversion with acceptable loan approval rates.\n",
    "7. **Ensemble Methods:** Explore ensemble techniques that can improve recall without severely impacting precision.\n",
    "8. **Cost-Sensitive Learning:** Incorporate misclassification costs to reflect the higher cost of false negatives, aligning the model's objective with the business goal of minimizing financial losses.\n",
    "\n",
    "By the end of this notebook, we aim to have a model (or ensemble of models) that excels at identifying potential loan defaulters, providing the bank with a powerful tool for risk assessment and mitigation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import (\n",
    "    train_test_split,\n",
    "    StratifiedKFold,\n",
    "    GridSearchCV,\n",
    "    RandomizedSearchCV,\n",
    "    cross_val_score,\n",
    ")\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "import xgboost as xgb\n",
    "from sklearn.metrics import (\n",
    "    classification_report,\n",
    "    roc_auc_score,\n",
    "    precision_recall_curve,\n",
    "    auc,\n",
    "    confusion_matrix,\n",
    "    ConfusionMatrixDisplay,\n",
    "    f1_score\n",
    ")\n",
    "\n",
    "from retail_bank_risk.model_training_utils import downscale_dtypes\n",
    "\n",
    "from sklearn.metrics import make_scorer, recall_score\n",
    "from joblib import Parallel, delayed\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_parquet(\n",
    "    \"../data/processed/application_train_engineered.parquet\"\n",
    ")\n",
    "test_df = pd.read_parquet(\n",
    "    \"../data/processed/application_test_engineered.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Shape: (307511, 77)\n",
      "Test Data Shape: (48744, 76)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reg_city_not_work_city_0</th>\n",
       "      <th>reg_city_not_work_city_1</th>\n",
       "      <th>region_rating_client_w_city</th>\n",
       "      <th>region_rating_client</th>\n",
       "      <th>name_contract_type_cash loans</th>\n",
       "      <th>name_contract_type_revolving loans</th>\n",
       "      <th>code_gender_m</th>\n",
       "      <th>code_gender_f</th>\n",
       "      <th>flag_own_car_n</th>\n",
       "      <th>flag_own_car_y</th>\n",
       "      <th>...</th>\n",
       "      <th>is_anomaly_true</th>\n",
       "      <th>age_group</th>\n",
       "      <th>income_group</th>\n",
       "      <th>credit_amount_group</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>credit_to_goods_ratio</th>\n",
       "      <th>annuity_to_income_ratio</th>\n",
       "      <th>ext_source_mean</th>\n",
       "      <th>credit_exceeds_goods</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.007889</td>\n",
       "      <td>1.158397</td>\n",
       "      <td>0.121978</td>\n",
       "      <td>0.201162</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.790750</td>\n",
       "      <td>1.145199</td>\n",
       "      <td>0.132217</td>\n",
       "      <td>0.588812</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.642739</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.316167</td>\n",
       "      <td>1.052803</td>\n",
       "      <td>0.219900</td>\n",
       "      <td>0.680460</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.222222</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.179963</td>\n",
       "      <td>0.397760</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 77 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   reg_city_not_work_city_0  reg_city_not_work_city_1  \\\n",
       "0                         1                         0   \n",
       "1                         1                         0   \n",
       "2                         1                         0   \n",
       "3                         1                         0   \n",
       "4                         0                         1   \n",
       "\n",
       "   region_rating_client_w_city  region_rating_client  \\\n",
       "0                          1.0                   1.0   \n",
       "1                          2.0                   2.0   \n",
       "2                          1.0                   1.0   \n",
       "3                          1.0                   1.0   \n",
       "4                          1.0                   1.0   \n",
       "\n",
       "   name_contract_type_cash loans  name_contract_type_revolving loans  \\\n",
       "0                              1                                   0   \n",
       "1                              1                                   0   \n",
       "2                              0                                   1   \n",
       "3                              1                                   0   \n",
       "4                              1                                   0   \n",
       "\n",
       "   code_gender_m  code_gender_f  flag_own_car_n  flag_own_car_y  ...  \\\n",
       "0              1              0               1               0  ...   \n",
       "1              0              1               1               0  ...   \n",
       "2              1              0               0               1  ...   \n",
       "3              0              1               1               0  ...   \n",
       "4              1              0               1               0  ...   \n",
       "\n",
       "   is_anomaly_true  age_group  income_group  credit_amount_group  \\\n",
       "0                0        1.0           3.0                  1.0   \n",
       "1                0        3.0           4.0                  4.0   \n",
       "2                0        3.0           0.0                  0.0   \n",
       "3                0        3.0           1.0                  1.0   \n",
       "4                0        3.0           1.0                  2.0   \n",
       "\n",
       "   debt_to_income_ratio  credit_to_goods_ratio  annuity_to_income_ratio  \\\n",
       "0              2.007889               1.158397                 0.121978   \n",
       "1              4.790750               1.145199                 0.132217   \n",
       "2              2.000000               1.000000                 0.100000   \n",
       "3              2.316167               1.052803                 0.219900   \n",
       "4              4.222222               1.000000                 0.179963   \n",
       "\n",
       "   ext_source_mean  credit_exceeds_goods  target  \n",
       "0         0.201162                     1       1  \n",
       "1         0.588812                     1       0  \n",
       "2         0.642739                     0       0  \n",
       "3         0.680460                     1       0  \n",
       "4         0.397760                     0       0  \n",
       "\n",
       "[5 rows x 77 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f\"Training Data Shape: {train_df.shape}\")\n",
    "print(f\"Test Data Shape: {test_df.shape}\")\n",
    "\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems everything fine, encoded variables are saved, new features created, shapes align with the expected setup.\n",
    "\n",
    "Next, we can downscale feature dtypes for last time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 307511 entries, 0 to 307510\n",
      "Data columns (total 77 columns):\n",
      " #   Column                                   Non-Null Count   Dtype   \n",
      "---  ------                                   --------------   -----   \n",
      " 0   reg_city_not_work_city_0                 307511 non-null  uint8   \n",
      " 1   reg_city_not_work_city_1                 307511 non-null  uint8   \n",
      " 2   region_rating_client_w_city              307511 non-null  float32 \n",
      " 3   region_rating_client                     307511 non-null  float32 \n",
      " 4   name_contract_type_cash loans            307511 non-null  uint8   \n",
      " 5   name_contract_type_revolving loans       307511 non-null  uint8   \n",
      " 6   code_gender_m                            307511 non-null  uint8   \n",
      " 7   code_gender_f                            307511 non-null  uint8   \n",
      " 8   flag_own_car_n                           307511 non-null  uint8   \n",
      " 9   flag_own_car_y                           307511 non-null  uint8   \n",
      " 10  flag_own_realty_y                        307511 non-null  uint8   \n",
      " 11  flag_own_realty_n                        307511 non-null  uint8   \n",
      " 12  name_type_suite_unaccompanied            307511 non-null  uint8   \n",
      " 13  name_type_suite_family                   307511 non-null  uint8   \n",
      " 14  name_type_suite_spouse, partner          307511 non-null  uint8   \n",
      " 15  name_type_suite_children                 307511 non-null  uint8   \n",
      " 16  name_type_suite_other_a                  307511 non-null  uint8   \n",
      " 17  name_type_suite_mode                     307511 non-null  uint8   \n",
      " 18  name_type_suite_other_b                  307511 non-null  uint8   \n",
      " 19  name_type_suite_group of people          307511 non-null  uint8   \n",
      " 20  name_income_type_working                 307511 non-null  uint8   \n",
      " 21  name_income_type_state servant           307511 non-null  uint8   \n",
      " 22  name_income_type_commercial associate    307511 non-null  uint8   \n",
      " 23  name_income_type_pensioner               307511 non-null  uint8   \n",
      " 24  name_income_type_unemployed              307511 non-null  uint8   \n",
      " 25  name_income_type_student                 307511 non-null  uint8   \n",
      " 26  name_income_type_businessman             307511 non-null  uint8   \n",
      " 27  name_income_type_maternity leave         307511 non-null  uint8   \n",
      " 28  name_education_type                      307511 non-null  float32 \n",
      " 29  name_family_status_single / not married  307511 non-null  uint8   \n",
      " 30  name_family_status_married               307511 non-null  uint8   \n",
      " 31  name_family_status_civil marriage        307511 non-null  uint8   \n",
      " 32  name_family_status_widow                 307511 non-null  uint8   \n",
      " 33  name_family_status_separated             307511 non-null  uint8   \n",
      " 34  name_family_status_unknown               307511 non-null  uint8   \n",
      " 35  name_housing_type_house / apartment      307511 non-null  uint8   \n",
      " 36  name_housing_type_rented apartment       307511 non-null  uint8   \n",
      " 37  name_housing_type_with parents           307511 non-null  uint8   \n",
      " 38  name_housing_type_municipal apartment    307511 non-null  uint8   \n",
      " 39  name_housing_type_office apartment       307511 non-null  uint8   \n",
      " 40  name_housing_type_co-op apartment        307511 non-null  uint8   \n",
      " 41  occupation_type                          307511 non-null  float32 \n",
      " 42  weekday_appr_process_start_wednesday     307511 non-null  uint8   \n",
      " 43  weekday_appr_process_start_monday        307511 non-null  uint8   \n",
      " 44  weekday_appr_process_start_thursday      307511 non-null  uint8   \n",
      " 45  weekday_appr_process_start_sunday        307511 non-null  uint8   \n",
      " 46  weekday_appr_process_start_saturday      307511 non-null  uint8   \n",
      " 47  weekday_appr_process_start_friday        307511 non-null  uint8   \n",
      " 48  weekday_appr_process_start_tuesday       307511 non-null  uint8   \n",
      " 49  organization_type                        307511 non-null  float32 \n",
      " 50  housetype_mode_block of flats            307511 non-null  uint8   \n",
      " 51  housetype_mode_mode                      307511 non-null  uint8   \n",
      " 52  housetype_mode_terraced house            307511 non-null  uint8   \n",
      " 53  housetype_mode_specific housing          307511 non-null  uint8   \n",
      " 54  emergencystate_mode_no                   307511 non-null  uint8   \n",
      " 55  emergencystate_mode_mode                 307511 non-null  uint8   \n",
      " 56  emergencystate_mode_yes                  307511 non-null  uint8   \n",
      " 57  days_last_phone_change                   307511 non-null  float32 \n",
      " 58  ext_source_2                             307511 non-null  float32 \n",
      " 59  ext_source_3                             307511 non-null  float32 \n",
      " 60  days_id_publish                          307511 non-null  float32 \n",
      " 61  days_birth                               307511 non-null  float32 \n",
      " 62  amt_income_total                         307511 non-null  float32 \n",
      " 63  amt_credit                               307511 non-null  float32 \n",
      " 64  amt_annuity                              307511 non-null  float32 \n",
      " 65  amt_goods_price                          307511 non-null  float32 \n",
      " 66  is_anomaly_false                         307511 non-null  uint8   \n",
      " 67  is_anomaly_true                          307511 non-null  uint8   \n",
      " 68  age_group                                307511 non-null  float32 \n",
      " 69  income_group                             307511 non-null  float32 \n",
      " 70  credit_amount_group                      307511 non-null  float32 \n",
      " 71  debt_to_income_ratio                     307511 non-null  float32 \n",
      " 72  credit_to_goods_ratio                    307511 non-null  float32 \n",
      " 73  annuity_to_income_ratio                  307511 non-null  float32 \n",
      " 74  ext_source_mean                          307511 non-null  float32 \n",
      " 75  credit_exceeds_goods                     307511 non-null  uint8   \n",
      " 76  target                                   307511 non-null  category\n",
      "dtypes: category(1), float32(21), uint8(55)\n",
      "memory usage: 41.1 MB\n"
     ]
    }
   ],
   "source": [
    "train_df, test_df = downscale_dtypes(train_df, test_df)\n",
    "\n",
    "train_df.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Features: 76\n",
      "Feature Names: ['reg_city_not_work_city_0', 'reg_city_not_work_city_1', 'region_rating_client_w_city', 'region_rating_client', 'name_contract_type_cash loans', 'name_contract_type_revolving loans', 'code_gender_m', 'code_gender_f', 'flag_own_car_n', 'flag_own_car_y', 'flag_own_realty_y', 'flag_own_realty_n', 'name_type_suite_unaccompanied', 'name_type_suite_family', 'name_type_suite_spouse, partner', 'name_type_suite_children', 'name_type_suite_other_a', 'name_type_suite_mode', 'name_type_suite_other_b', 'name_type_suite_group of people', 'name_income_type_working', 'name_income_type_state servant', 'name_income_type_commercial associate', 'name_income_type_pensioner', 'name_income_type_unemployed', 'name_income_type_student', 'name_income_type_businessman', 'name_income_type_maternity leave', 'name_education_type', 'name_family_status_single / not married', 'name_family_status_married', 'name_family_status_civil marriage', 'name_family_status_widow', 'name_family_status_separated', 'name_family_status_unknown', 'name_housing_type_house / apartment', 'name_housing_type_rented apartment', 'name_housing_type_with parents', 'name_housing_type_municipal apartment', 'name_housing_type_office apartment', 'name_housing_type_co-op apartment', 'occupation_type', 'weekday_appr_process_start_wednesday', 'weekday_appr_process_start_monday', 'weekday_appr_process_start_thursday', 'weekday_appr_process_start_sunday', 'weekday_appr_process_start_saturday', 'weekday_appr_process_start_friday', 'weekday_appr_process_start_tuesday', 'organization_type', 'housetype_mode_block of flats', 'housetype_mode_mode', 'housetype_mode_terraced house', 'housetype_mode_specific housing', 'emergencystate_mode_no', 'emergencystate_mode_mode', 'emergencystate_mode_yes', 'days_last_phone_change', 'ext_source_2', 'ext_source_3', 'days_id_publish', 'days_birth', 'amt_income_total', 'amt_credit', 'amt_annuity', 'amt_goods_price', 'is_anomaly_false', 'is_anomaly_true', 'age_group', 'income_group', 'credit_amount_group', 'debt_to_income_ratio', 'credit_to_goods_ratio', 'annuity_to_income_ratio', 'ext_source_mean', 'credit_exceeds_goods']\n"
     ]
    }
   ],
   "source": [
    "X = train_df.drop(\"target\", axis=1)\n",
    "y = train_df[\"target\"]\n",
    "\n",
    "print(f\"Number of Features: {X.shape[1]}\")\n",
    "print(\"Feature Names:\", X.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Set Shape: (246008, 76)\n",
      "Validation Set Shape: (61503, 76)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "print(f\"Training Set Shape: {X_train.shape}\")\n",
    "print(f\"Validation Set Shape: {X_val.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prioritize recall to identify as many defaulters as possible."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "recall_scorer = make_scorer(recall_score, pos_label=1, zero_division=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define pipelines for different models.\n",
    "\n",
    "This way, we ensure the same preprocessing steps are applied within each model's evaluation during cross-validation, preventing data leakage and making results more reliable.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_lr = Pipeline([\n",
    "    ('scaler', StandardScaler()),\n",
    "    ('classifier', LogisticRegression(random_state=42, max_iter=1000))\n",
    "])\n",
    "\n",
    "# Decision Tree Pipeline\n",
    "pipeline_dt = Pipeline([\n",
    "    ('classifier', DecisionTreeClassifier(random_state=42))\n",
    "])\n",
    "\n",
    "# Random Forest Pipeline\n",
    "pipeline_rf = Pipeline([\n",
    "    ('classifier', RandomForestClassifier(random_state=42, n_jobs=-1))\n",
    "])\n",
    "\n",
    "# XGBoost Pipeline\n",
    "pipeline_xgb = Pipeline([\n",
    "    ('classifier', xgb.XGBClassifier(\n",
    "        objective=\"binary:logistic\",\n",
    "        use_label_encoder=False,\n",
    "        eval_metric='logloss',\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    ))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define parameter grids for each model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression Parameter Grid\n",
    "param_grid_lr = {\n",
    "    'classifier__C': [0.001, 0.01, 0.1, 1, 10, 100],\n",
    "    'classifier__class_weight': ['balanced', {0:1, 1:2}, {0:1, 1:5}, {0:1, 1:10}],\n",
    "    'classifier__penalty': ['l1', 'l2'],  # Removed 'elasticnet' and 'none'\n",
    "    'classifier__solver': ['liblinear', 'saga']  # Solvers compatible with 'l1' and 'l2'\n",
    "}\n",
    "\n",
    "# Decision Tree Parameter Grid\n",
    "param_grid_dt = {\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': ['balanced', {0:1, 1:2}, {0:1, 1:5}, {0:1, 1:10}]\n",
    "}\n",
    "\n",
    "# Random Forest Parameter Grid\n",
    "param_grid_rf = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__max_depth': [None, 10, 20, 30],\n",
    "    'classifier__min_samples_split': [2, 5, 10],\n",
    "    'classifier__min_samples_leaf': [1, 2, 4],\n",
    "    'classifier__class_weight': ['balanced', {0:1, 1:2}, {0:1, 1:5}, {0:1, 1:10}]\n",
    "}\n",
    "\n",
    "# XGBoost Parameter Grid\n",
    "param_grid_xgb = {\n",
    "    'classifier__n_estimators': [50, 100, 200],\n",
    "    'classifier__learning_rate': [0.01, 0.1, 0.3],\n",
    "    'classifier__max_depth': [3, 5, 7],\n",
    "    'classifier__scale_pos_weight': [1, 2, 5, 10]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting Grid Search for Logistic Regression...\n",
      "Fitting 5 folds for each of 96 candidates, totalling 480 fits\n",
      "Grid Search failed for Logistic Regression with error: pos_label=1 is not a valid label: It should be one of ['0' '1']\n",
      "\n",
      "Starting Grid Search for Decision Tree...\n",
      "Fitting 5 folds for each of 144 candidates, totalling 720 fits\n",
      "Grid Search failed for Decision Tree with error: pos_label=1 is not a valid label: It should be one of ['0' '1']\n",
      "\n",
      "Starting Grid Search for Random Forest...\n",
      "Fitting 5 folds for each of 432 candidates, totalling 2160 fits\n",
      "Grid Search failed for Random Forest with error: pos_label=1 is not a valid label: It should be one of ['0' '1']\n",
      "\n",
      "Starting Grid Search for XGBoost...\n",
      "Fitting 5 folds for each of 108 candidates, totalling 540 fits\n",
      "Grid Search failed for XGBoost with error: Invalid classes inferred from unique values of `y`.  Expected: [0 1], got ['0' '1']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pipelines = [pipeline_lr, pipeline_dt, pipeline_rf, pipeline_xgb]\n",
    "param_grids = [param_grid_lr, param_grid_dt, param_grid_rf, param_grid_xgb]\n",
    "model_names = ['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost']\n",
    "best_estimators = []\n",
    "\n",
    "# Define Stratified K-Fold Cross-Validation\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "# Perform Grid Search for each model with parallel processing\n",
    "for name, pipeline, param_grid in zip(model_names, pipelines, param_grids):\n",
    "    print(f\"Starting Grid Search for {name}...\")\n",
    "    grid_search = GridSearchCV(\n",
    "        pipeline,\n",
    "        param_grid=param_grid,\n",
    "        cv=kfold,\n",
    "        scoring=recall_scorer,\n",
    "        n_jobs=-1,  # Utilize all available cores\n",
    "        verbose=2,\n",
    "        error_score='raise'  # Raise errors to debug\n",
    "    )\n",
    "    try:\n",
    "        grid_search.fit(X_train, y_train)\n",
    "        best_estimators.append(grid_search.best_estimator_)\n",
    "        print(f\"Best parameters for {name}: {grid_search.best_params_}\")\n",
    "        print(f\"Best recall score: {grid_search.best_score_:.4f}\\n\")\n",
    "    except Exception as e:\n",
    "        print(f\"Grid Search failed for {name} with error: {e}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, model in zip(model_names, best_estimators):\n",
    "    print(f\"Evaluating {name}...\")\n",
    "\n",
    "    # Cross-validated recall\n",
    "    cv_results = cross_val_score(\n",
    "        model,\n",
    "        X_train,\n",
    "        y_train,\n",
    "        cv=kfold,\n",
    "        scoring=recall_scorer,\n",
    "        n_jobs=-1  # Utilize all cores\n",
    "    )\n",
    "    print(f\"{name} Cross-Validated Recall: {cv_results.mean():.4f} (± {cv_results.std():.4f})\")\n",
    "\n",
    "    # Predictions on Validation Set\n",
    "    y_pred = model.predict(X_val)\n",
    "    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
    "\n",
    "    # Classification Report\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_val, y_pred))\n",
    "\n",
    "    # Precision-Recall AUC\n",
    "    precision, recall, thresholds = precision_recall_curve(y_val, y_pred_proba)\n",
    "    pr_auc = auc(recall, precision)\n",
    "    print(f\"AUC-PR: {pr_auc:.4f}\")\n",
    "\n",
    "    # ROC AUC\n",
    "    roc_auc = roc_auc_score(y_val, y_pred_proba)\n",
    "    print(f\"AUC-ROC: {roc_auc:.4f}\")\n",
    "\n",
    "    # F1 Score\n",
    "    f1 = f1_score(y_val, y_pred)\n",
    "    print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "    # Confusion Matrix\n",
    "    cm = confusion_matrix(y_val, y_pred)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(307511, 77)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Overview\n",
    "\n",
    "This notebook builds upon the insights gained from the previous notebook (`03_exploratory_data_analysis.ipynb`) and focuses on **Feature Engineering**. This stage involves creating new features and transforming existing ones based on our statistical findings and domain knowledge to enhance our credit risk model.\n",
    "\n",
    "### 0.4.1 Objectives\n",
    "\n",
    "The main objectives of this notebook are:\n",
    "\n",
    "1. **Leverage EDA Insights:** Utilize the patterns and relationships uncovered in our exploratory data analysis to guide our feature engineering efforts.\n",
    "2. **Create Non-Linear Transformations:** Develop binned versions of continuous variables to capture non-linear relationships with the target variable.\n",
    "3. **Implement Domain-Specific Features:** Create new features based on financial domain knowledge that are known to be relevant in credit risk assessment.\n",
    "4. **Enhance Model Input:** Generate features that can potentially improve our model's predictive power and interpretability.\n",
    "5. **Prepare for Modeling:** Finalize the feature set that will be used in our subsequent modeling efforts.\n",
    "\n",
    "### 0.4.2 Importance of Feature Engineering\n",
    "\n",
    "Feature engineering plays a crucial role in improving machine learning model performance:\n",
    "\n",
    "- **Capture Complex Relationships:** Engineered features can help models capture non-linear and intricate relationships that may not be apparent in the raw data.\n",
    "- **Incorporate Domain Knowledge:** It allows us to inject domain expertise into our data, potentially improving model performance and interpretability.\n",
    "- **Improve Model Generalization:** Well-engineered features can help models generalize better to unseen data.\n",
    "- **Enhance Interpretability:** Carefully crafted features can make model predictions more understandable and actionable for stakeholders.\n",
    "\n",
    "### 0.4.3 Our Approach\n",
    "\n",
    "In this notebook, we will focus on the following feature engineering tasks:\n",
    "\n",
    "1. **Age Binning:** Create age groups (18-25, 26-35, 36-45, 46-55, 56-65, 65+) to capture non-linear relationships with default risk.\n",
    "2. **Financial Ratios:** Implement key financial ratios including:\n",
    "   - Debt-to-income ratio\n",
    "   - Credit-to-goods price ratio\n",
    "   - Annuity-to-income ratio\n",
    "3. **Stability Indicators:** Derive new features such as:\n",
    "   - Employed-to-age ratio\n",
    "   - Flag for when credit amount exceeds goods price\n",
    "4. **Credit Score Aggregation:** Generate an average of external source scores for a more stable overall credit score indicator.\n",
    "5. **Income and Credit Amount Binning:** Create bins for income and credit amount variables to identify potential threshold effects and improve model robustness to outliers.\n",
    "\n",
    "By the end of this notebook, we will have a rich set of engineered features that leverage both our data-driven insights and domain knowledge, setting a strong foundation for our subsequent modeling efforts.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import warnings\n",
    "\n",
    "from retail_bank_risk.feature_engineering_utils import (\n",
    "    create_binned_features,\n",
    "    create_derived_features,\n",
    "    encode_categorical_features,\n",
    ")\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train = pd.read_parquet(\n",
    "    \"../data/processed/application_train_prepared.parquet\"\n",
    ")\n",
    "application_test = pd.read_parquet(\n",
    "    \"../data/processed/application_test_prepared.parquet\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use the `create_binned_features` function to transform continuous numerical variables into categorical bins, simplifying the dataset.4\n",
    "\n",
    "This function will bin the `days_birth` column into predefined age groups, converting age (expressed in days) into meaningful categories like \"18-25\" and \"65+\".\n",
    "\n",
    "We will also use it to bin the `amt_income_total` and `amt_credit` columns into quantile-based groups, ensuring approximately equal representation in each bin.\n",
    "\n",
    "This binning will help mitigate the impact of outliers and capture non-linear relationships between these variables and the target variable.\n",
    "\n",
    "Ultimately, this process will enhance model interpretability and stability by grouping continuous data into manageable segments.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_engineered = create_binned_features(application_train)\n",
    "application_test_engineered = create_binned_features(application_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After binning the data, we will apply one-hot encoding to the categorical features. Features with more than two categories will be encoded separately. We will also separate the target variable from the encoded features.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe_features = [\n",
    "    \"reg_city_not_work_city\",  # Binary, 2 distinct values\n",
    "    \"name_contract_type\",  # Binary, 2 distinct values\n",
    "    \"code_gender\",  # Binary, 2 distinct values\n",
    "    \"flag_own_car\",  # Binary, 2 distinct values\n",
    "    \"flag_own_realty\",  # Binary, 2 distinct values\n",
    "    \"name_type_suite\",  # 8 distinct values\n",
    "    \"name_income_type\",  # 8 distinct values\n",
    "    \"name_education_type\",  # 5 distinct values\n",
    "    \"name_family_status\",  # 6 distinct values\n",
    "    \"name_housing_type\",  # 6 distinct values\n",
    "    \"weekday_appr_process_start\",  # 7 distinct values\n",
    "    \"housetype_mode\",  # 4 distinct values\n",
    "    \"emergencystate_mode\",  # 3 distinct values\n",
    "    \"is_anomaly\",  # Binary, 2 distinct values\n",
    "]\n",
    "\n",
    "target_encoded_features = [\n",
    "    \"region_rating_client_w_city\",  # 3 distinct values\n",
    "    \"region_rating_client\",  # 3 distinct values\n",
    "    \"occupation_type\",  # 19 distinct values\n",
    "    \"organization_type\",  # 58 distinct values\n",
    "]\n",
    "\n",
    "target_feature = \"target\"  # Binary target with 0 and 1 values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now generate new features using the `create_derived_features` function.\n",
    "\n",
    "This function will calculate key financial ratios, including `debt_to_income_ratio`, `credit_to_goods_ratio`, and `annuity_to_income_ratio`, to provide insights into applicants' financial health.\n",
    "\n",
    "We will also create `ext_source_mean` by averaging external source scores for a consolidated measure of external assessments.\n",
    "\n",
    "Furthermore, we will generate a binary flag, `credit_exceeds_goods`, to indicate instances where the credit amount surpasses the value of the goods purchased.\n",
    "\n",
    "These derived features will improve the dataset's predictive power by capturing important financial relationships.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_engineered = create_derived_features(application_train)\n",
    "application_test_engineered = create_derived_features(application_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we will use the `encode_categorical_features` function to transform categorical variables into a numerical format suitable for machine learning.\n",
    "\n",
    "This function will apply one-hot encoding to low-cardinality features, creating binary columns for each category and effectively handling unknown categories. For high-cardinality features, leave-one-out encoding will be used, replacing each category with the mean of the target variable.\n",
    "\n",
    "This approach captures the relationship between the categories and the target.\n",
    "\n",
    "The function ensures consistency between the training and testing datasets by aligning the encoded columns and removing any unwanted or constant columns.\n",
    "\n",
    "This final encoding step prepares the data for model training by preserving valuable information while managing dimensionality.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_encoded, application_test_encoded = (\n",
    "    encode_categorical_features(\n",
    "        application_train_engineered,\n",
    "        application_test_engineered,\n",
    "        ohe_features,\n",
    "        target_encoded_features,\n",
    "        target_feature,\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. **Binning Continuous Variables:** Transformed age, income, and credit amount into categorical bins to simplify models and handle outliers.\n",
    "2. **Creating Derived Features:** Generated financial ratios and indicators to capture complex relationships and domain-specific insights.\n",
    "3. **Encoding Categorical Variables:** Applied One-Hot and Leave-One-Out Encoding to convert categorical features into numerical formats suitable for modeling, ensuring consistency and effectively handling high-cardinality features.\n",
    "\n",
    "These steps improve the dataset's quality and relevance for more accurate and robust machine learning models.\n",
    "\n",
    "We will save the processed data to parquet files for efficient storage and retrieval.\n",
    "\n",
    "Next, we'll move on to modeling in the `05_model_training_and_evaluation.ipynb` notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "application_train_encoded.to_parquet(\"../data/processed/application_train_engineered.parquet\")\n",
    "application_test_encoded.to_parquet(\"../data/processed/application_test_engineered.parquet\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
